{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform, sys, time\n",
    "from datetime import date\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import face_recognition\n",
    "import imutils\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Activation, AveragePooling2D\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "#import screen_brightness_control as sbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img, model):\n",
    "    img = np.array(Image.fromarray(img, 'RGB').convert('L'))\n",
    "    cv2.imshow(\"prediction\" , img)\n",
    "    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE)).astype('float32')\n",
    "    img /= 255\n",
    "    img = img.reshape(1,IMG_SIZE,IMG_SIZE,1)\n",
    "    prediction = model.predict(img)\n",
    "    ##print(prediction)\n",
    "    if prediction < 0.1:\n",
    "        prediction = 'closed'\n",
    "    elif prediction > 0.9:\n",
    "        prediction = 'open'\n",
    "    else:\n",
    "        prediction = 'idk'\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    face_cascPath = 'haarcascade_frontalface_alt.xml'\n",
    "    open_eye_cascPath = \"haarcascade_eye.xml\"\n",
    "    open_eyeglasses_cascPath = 'haarcascade_eye_tree_eyeglasses.xml'\n",
    "    left_eye_cascPath = 'haarcascade_lefteye_2splits.xml'\n",
    "    right_eye_cascPath ='haarcascade_righteye_2splits.xml'\n",
    "\n",
    "    face_detector = cv2.CascadeClassifier(cv2.data.haarcascades+face_cascPath)\n",
    "    open_eyes_detector = cv2.CascadeClassifier(cv2.data.haarcascades+open_eye_cascPath)\n",
    "    open_eyesglasses_detector = cv2.CascadeClassifier(cv2.data.haarcascades+open_eyeglasses_cascPath)\n",
    "    left_eye_detector = cv2.CascadeClassifier(cv2.data.haarcascades+left_eye_cascPath)\n",
    "    right_eye_detector = cv2.CascadeClassifier(cv2.data.haarcascades+right_eye_cascPath)\n",
    "\n",
    "    model = Sequential([Conv2D(6, (3,3), input_shape = (24,24,1)),\n",
    "                       Activation(\"relu\"),\n",
    "                       AveragePooling2D(),\n",
    "                       Conv2D(16, (3,3), input_shape = (24,24,1)),\n",
    "                       Activation(\"relu\"),\n",
    "                       AveragePooling2D(),\n",
    "                       Flatten(),\n",
    "                       Dense(120),\n",
    "                       Activation('relu'),\n",
    "                       Dense(84),\n",
    "                       Activation('relu'),\n",
    "                       Dense(1),\n",
    "                       Activation('sigmoid')\n",
    "                      ])\n",
    "    model.load_weights(\"eye_status.h5\")\n",
    "\n",
    "\n",
    "    print(\"[LOG] Collecting images ...\")\n",
    "    images = []\n",
    "    for direc, _, files in tqdm(os.walk(\"ImagesTrain\")):\n",
    "        for file in files:\n",
    "            if file.endswith(\"jpeg\") or file.endswith(\"jpg\"):\n",
    "                images.append(os.path.join(direc,file))\n",
    "    return (model,face_detector, open_eyes_detector, open_eyesglasses_detector, left_eye_detector, right_eye_detector, images) \n",
    "\n",
    "def process_and_encode(images):\n",
    "    # initialize the list of known encodings and known names\n",
    "    known_encodings = []\n",
    "    known_names = []\n",
    "    print(\"[LOG] Encoding faces ...\")\n",
    "\n",
    "    for image_path in tqdm(images):\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        # Convert it from BGR to RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "     \n",
    "        # detect face in the image and get its location (square boxes coordinates)\n",
    "        boxes = face_recognition.face_locations(image, model='hog')\n",
    "\n",
    "        # Encode the face into a 128-d embeddings vector\n",
    "        encoding = face_recognition.face_encodings(image, boxes)\n",
    "\n",
    "        # the person's name is the name of the folder where the image comes from\n",
    "        name = image_path.split(os.path.sep)[-1]\n",
    "\n",
    "        if len(encoding) > 0 : \n",
    "            known_encodings.append(encoding[0])\n",
    "            known_names.append(name)\n",
    "\n",
    "    return {\"encodings\": known_encodings, \"names\": known_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBlinking(history, maxFrames):\n",
    "    \"\"\" @history: A string containing the history of eyes status \n",
    "         where a '1' means that the eyes were closed and '0' open.\n",
    "        @maxFrames: The maximal number of successive frames where an eye is closed \"\"\"\n",
    "    print(history)\n",
    "    for i in range(maxFrames):\n",
    "        pattern = '1' + '0'*(i+1) + '1'\n",
    "        if pattern in history:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def detect_and_display(model, frame, face_detector, open_eyes_detector, open_eyesglasses_detector, left_eye_detector, right_eye_detector, data, eyes_detected):\n",
    "        # resize the frame\n",
    "        frame = cv2.resize(frame, (0, 0), fx=0.6, fy=0.6)\n",
    "            \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = face_detector.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(50, 50),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "\n",
    "        # for each detected face\n",
    "        for (x,y,w,h) in faces:\n",
    "            # Encode the face into a 128-d embeddings vector\n",
    "            encoding = face_recognition.face_encodings(rgb, [(y, x+w, y+h, x)])[0]\n",
    "\n",
    "            # Compare the vector with all known faces encodings\n",
    "            matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "\n",
    "            # For now we don't know the person name\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # If there is at least one match:\n",
    "            if True in matches:\n",
    "                matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "                counts = {}\n",
    "                for i in matchedIdxs:\n",
    "                    name = data[\"names\"][i]\n",
    "                    counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "                # determine the recognized face with the largest number of votes\n",
    "                name = max(counts, key=counts.get)\n",
    "\n",
    "            face = frame[y:y+h,x:x+w]\n",
    "            gray_face = gray[y:y+h,x:x+w]\n",
    "\n",
    "            eyes = []\n",
    "            \n",
    "            # Eyes detection\n",
    "            # check first if eyes are open (with glasses taking into account)\n",
    "            '''open_eyes_glasses = open_eyesglasses_detector.detectMultiScale(\n",
    "                gray_face,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30),\n",
    "                flags = cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "            \n",
    "            open_eyes = open_eyes_detector.detectMultiScale(\n",
    "                gray_face,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30),\n",
    "                flags = cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "            '''\n",
    "            # if open_eyes_glasses detect eyes then they are open \n",
    "            open_eyes_glasses = []\n",
    "            open_eyes = []\n",
    "            if len(open_eyes_glasses) == 2 or len(open_eyes)==2:\n",
    "                eyes_detected[name]+='1'\n",
    "                for (ex,ey,ew,eh) in open_eyes_glasses:\n",
    "                    cv2.rectangle(face,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            \n",
    "            # otherwise try detecting eyes using left and right_eye_detector\n",
    "            # which can detect open and closed eyes                \n",
    "            else:\n",
    "                # separate the face into left and right sides\n",
    "                left_face = frame[y:y+h, x+int(w/2):x+w]\n",
    "                left_face_gray = gray[y:y+h, x+int(w/2):x+w]\n",
    "\n",
    "                right_face = frame[y:y+h, x:x+int(w/2)]\n",
    "                right_face_gray = gray[y:y+h, x:x+int(w/2)]\n",
    "\n",
    "                # Detect the left eye\n",
    "                left_eye = left_eye_detector.detectMultiScale(\n",
    "                    left_face_gray,\n",
    "                    scaleFactor=1.1,\n",
    "                    minNeighbors=5,\n",
    "                    minSize=(30, 30),\n",
    "                    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "\n",
    "                # Detect the right eye\n",
    "                right_eye = right_eye_detector.detectMultiScale(\n",
    "                    right_face_gray,\n",
    "                    scaleFactor=1.1,\n",
    "                    minNeighbors=5,\n",
    "                    minSize=(30, 30),\n",
    "                    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "                eye_status = '1'\n",
    "                closed = True # we suppose the eyes are open\n",
    "\n",
    "                # For each eye check wether the eye is closed.\n",
    "                # If one is closed we conclude the eyes are closed\n",
    "                for (ex,ey,ew,eh) in right_eye:\n",
    "                    color = (0,255,0)\n",
    "                    cv2.imshow(\"eye_right\", right_face[ey:ey+eh,ex:ex+ew] )\n",
    "                    pred = predict(right_face[ey:ey+eh,ex:ex+ew],model)\n",
    "                    if pred == 'closed': \n",
    "                        print('right closed')\n",
    "                        color = (0,0,255)\n",
    "                    else:\n",
    "                        closed = False\n",
    "                    cv2.rectangle(right_face,(ex,ey),(ex+ew,ey+eh),color,2)\n",
    "                for (ex,ey,ew,eh) in left_eye:\n",
    "                    color = (0,255,0)\n",
    "                    cv2.imshow(\"eye_left\", left_face[ey:ey+eh,ex:ex+ew] )\n",
    "                    pred = predict(left_face[ey:ey+eh,ex:ex+ew],model)\n",
    "                    if pred == 'closed':\n",
    "                        print('left closed')\n",
    "                        color = (0,0,255)\n",
    "                    else:\n",
    "                        closed = False\n",
    "                    cv2.rectangle(left_face,(ex,ey),(ex+ew,ey+eh),color,2)\n",
    "                if closed:\n",
    "                    eye_status = '0'\n",
    "                eyes_detected[name] += eye_status\n",
    "            # Each time, we check if the person has blinked\n",
    "            # If yes, we display its name\n",
    "            print(name ,eyes)\n",
    "            if isBlinking(eyes_detected[name],3):\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                # Display name\n",
    "                y = y - 15 if y - 15 > 15 else y + 15\n",
    "                cv2.putText(frame, name+\"is blinking\", (x, y), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)\n",
    "                #plt.imshow(frame)\n",
    "                #plt.show()\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Collecting images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 686.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Encoding faces ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "(model, face_detector, open_eyes_detector,open_eyesglasses_detector, left_eye_detector, right_eye_detector, images) = init()\n",
    "data = process_and_encode(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame\n",
      "frame\n",
      "[[0.9303294]]\n",
      "[[0.21622992]]\n",
      "Kopal.jpg []\n",
      "1\n",
      "frame\n",
      "[[0.01604348]]\n",
      "right closed\n",
      "[[0.02952766]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "10\n",
      "frame\n",
      "[[0.4455178]]\n",
      "[[0.15302226]]\n",
      "Kopal.jpg []\n",
      "101\n",
      "frame\n",
      "[[0.5711021]]\n",
      "[[0.14863414]]\n",
      "Kopal.jpg []\n",
      "1011\n",
      "frame\n",
      "[[0.0073486]]\n",
      "right closed\n",
      "[[0.00803125]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "10110\n",
      "frame\n",
      "[[0.5685756]]\n",
      "[[0.09137109]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "101101\n",
      "frame\n",
      "[[0.6409192]]\n",
      "[[0.4221521]]\n",
      "Kopal.jpg []\n",
      "1011011\n",
      "frame\n",
      "[[0.87869763]]\n",
      "[[0.37168053]]\n",
      "Kopal.jpg []\n",
      "10110111\n",
      "frame\n",
      "[[0.14915228]]\n",
      "[[0.06827685]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "101101111\n",
      "frame\n",
      "[[0.5095161]]\n",
      "[[0.23230046]]\n",
      "Kopal.jpg []\n",
      "1011011111\n",
      "frame\n",
      "[[0.74268717]]\n",
      "[[0.21533686]]\n",
      "Kopal.jpg []\n",
      "10110111111\n",
      "frame\n",
      "[[0.00650111]]\n",
      "right closed\n",
      "[[0.00488302]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "101101111110\n",
      "frame\n",
      "[[0.4950057]]\n",
      "[[0.51001304]]\n",
      "Kopal.jpg []\n",
      "1011011111101\n",
      "frame\n",
      "[[0.49951065]]\n",
      "[[0.20999613]]\n",
      "Kopal.jpg []\n",
      "10110111111011\n",
      "frame\n",
      "[[0.826674]]\n",
      "[[0.6120563]]\n",
      "Kopal.jpg []\n",
      "101101111110111\n",
      "frame\n",
      "[[0.78941315]]\n",
      "[[0.2866348]]\n",
      "Kopal.jpg []\n",
      "1011011111101111\n",
      "frame\n",
      "[[0.6178928]]\n",
      "[[0.4955602]]\n",
      "Kopal.jpg []\n",
      "10110111111011111\n",
      "frame\n",
      "[[0.70993173]]\n",
      "[[0.36397678]]\n",
      "Kopal.jpg []\n",
      "101101111110111111\n",
      "frame\n",
      "[[0.3868793]]\n",
      "[[0.03672534]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "1011011111101111111\n",
      "frame\n",
      "[[0.21432889]]\n",
      "[[0.02351308]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "10110111111011111111\n",
      "frame\n",
      "[[0.52899235]]\n",
      "[[0.20629975]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111\n",
      "frame\n",
      "[[0.07925051]]\n",
      "right closed\n",
      "[[0.08119839]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "1011011111101111111110\n",
      "frame\n",
      "[[0.21597567]]\n",
      "[[0.09247482]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "10110111111011111111101\n",
      "frame\n",
      "[[0.08037001]]\n",
      "right closed\n",
      "[[0.03682154]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "101101111110111111111010\n",
      "frame\n",
      "[[0.8377806]]\n",
      "[[0.2606868]]\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101\n",
      "frame\n",
      "[[0.5749323]]\n",
      "[[0.3485263]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011\n",
      "frame\n",
      "[[0.30743003]]\n",
      "[[0.23402846]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111\n",
      "frame\n",
      "[[0.13485631]]\n",
      "[[0.07864356]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111\n",
      "frame\n",
      "[[0.37091854]]\n",
      "[[0.13759795]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111\n",
      "frame\n",
      "[[0.35655513]]\n",
      "[[0.30361342]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111\n",
      "frame\n",
      "[[0.04792652]]\n",
      "right closed\n",
      "[[0.01305455]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110\n",
      "frame\n",
      "[[0.36358026]]\n",
      "[[0.1722965]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101\n",
      "frame\n",
      "[[0.680777]]\n",
      "[[0.29488683]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011\n",
      "frame\n",
      "[[0.89231646]]\n",
      "[[0.6683098]]\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111\n",
      "frame\n",
      "[[0.22718254]]\n",
      "[[0.08614179]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111\n",
      "frame\n",
      "[[0.29049015]]\n",
      "[[0.25526968]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111\n",
      "frame\n",
      "[[0.5924134]]\n",
      "[[0.24213806]]\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111\n",
      "frame\n",
      "[[0.9678394]]\n",
      "[[0.47614512]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111\n",
      "frame\n",
      "[[0.00543731]]\n",
      "right closed\n",
      "[[0.00614685]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110\n",
      "frame\n",
      "[[0.4609661]]\n",
      "[[0.04592735]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101\n",
      "frame\n",
      "[[0.32571846]]\n",
      "[[0.34803677]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011\n",
      "frame\n",
      "[[0.451611]]\n",
      "[[0.43850026]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111\n",
      "frame\n",
      "[[0.0076876]]\n",
      "right closed\n",
      "[[0.01212755]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101110\n",
      "frame\n",
      "[[0.3639145]]\n",
      "[[0.2246804]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011101\n",
      "frame\n",
      "[[0.5723519]]\n",
      "[[0.22496438]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111011\n",
      "frame\n",
      "[[0.94155884]]\n",
      "[[0.4363184]]\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101110111\n",
      "frame\n",
      "[[0.71864325]]\n",
      "[[0.3007115]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011101111\n",
      "frame\n",
      "[[0.5298598]]\n",
      "[[0.4297574]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111011111\n",
      "frame\n",
      "[[0.68957937]]\n",
      "[[0.2988968]]\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101110111111\n",
      "frame\n",
      "[[0.6082063]]\n",
      "[[0.28237927]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011101111111\n",
      "frame\n",
      "[[0.61537087]]\n",
      "[[0.4177481]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111011111111\n",
      "frame\n",
      "[[0.77386266]]\n",
      "[[0.38384655]]\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101110111111111\n",
      "frame\n",
      "[[0.0063023]]\n",
      "right closed\n",
      "[[0.01147172]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011101111111110\n",
      "frame\n",
      "[[0.2777153]]\n",
      "[[0.50373906]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111011111111101\n",
      "frame\n",
      "[[0.28155792]]\n",
      "[[0.27398735]]\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101110111111111011\n",
      "frame\n",
      "[[0.91262937]]\n",
      "[[0.41232008]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011101111111110111\n",
      "frame\n",
      "[[0.29520184]]\n",
      "[[0.28122753]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111011111111101111\n",
      "frame\n",
      "[[0.02148563]]\n",
      "right closed\n",
      "[[0.02333102]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101110111111111011110\n",
      "frame\n",
      "[[0.13564938]]\n",
      "[[0.30072272]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011101111111110111101\n",
      "frame\n",
      "[[0.40655592]]\n",
      "[[0.45093113]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111011111111101111011\n",
      "frame\n",
      "[[0.00547311]]\n",
      "right closed\n",
      "[[0.01034614]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101110111111111011110110\n",
      "frame\n",
      "[[0.34698856]]\n",
      "[[0.14708805]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011101111111110111101101\n",
      "frame\n",
      "[[0.5024784]]\n",
      "[[0.39060393]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111011111111101111011011\n",
      "frame\n",
      "[[0.00336584]]\n",
      "right closed\n",
      "[[0.01075161]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101110111111111011110110110\n",
      "frame\n",
      "[[0.6924107]]\n",
      "[[0.2252222]]\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011101111111110111101101101\n",
      "frame\n",
      "[[0.29505575]]\n",
      "[[0.14102104]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111011111111101111011011011\n",
      "frame\n",
      "[[0.754075]]\n",
      "[[0.1637761]]\n",
      "Kopal.jpg []\n",
      "1011011111101111111110101111110111111101110111111111011110110110111\n",
      "frame\n",
      "[[0.02834788]]\n",
      "right closed\n",
      "[[0.03778452]]\n",
      "left closed\n",
      "Kopal.jpg []\n",
      "10110111111011111111101011111101111111011101111111110111101101101110\n",
      "frame\n",
      "[[0.661683]]\n",
      "[[0.15798056]]\n",
      "Kopal.jpg []\n",
      "101101111110111111111010111111011111110111011111111101111011011011101\n"
     ]
    }
   ],
   "source": [
    "eyes_detected = defaultdict(str)\n",
    "cap = cv2.VideoCapture(0)\n",
    "#initial_brightness = sbc.get_brightness()\n",
    "#sbc.set_brightness(75)\n",
    "while True:\n",
    "    ret , frame = cap.read()\n",
    "    #print(\"frame\")\n",
    "    frame = detect_and_display(model, frame, face_detector, open_eyes_detector,open_eyesglasses_detector, left_eye_detector, right_eye_detector, data, eyes_detected)\n",
    "    #plt.imshow(frame)\n",
    "    cv2.imshow(\"Live face detector\" , frame)\n",
    "    #plt.show()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "#sbc.set_brightness(initial_brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fr",
   "language": "python",
   "name": "fr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
